{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hari25483/Nail-Disease-Analysis/blob/main/Nail_severity_Mask_RCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fm1eXSwx-MOI"
      },
      "outputs": [],
      "source": [
        "# # Update CUDA for TF 2.5\n",
        "# !wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/libcudnn8_8.1.0.77-1+cuda11.2_amd64.deb\n",
        "# !dpkg -i libcudnn8_8.1.0.77-1+cuda11.2_amd64.deb\n",
        "# # Check if package has been installed\n",
        "# !ls -l /usr/lib/x86_64-linux-gnu/libcudnn.so.*\n",
        "# Upgrade Tensorflow\n",
        "# !pip install tensorflow==2.5.0 -f https://storage.googleapis.com/tf-debians/index.html\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "assert tensorflow.__version__ == '2.5.0'"
      ],
      "metadata": {
        "id": "slS1vZ666UKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Md87Hxgtn6zi"
      },
      "outputs": [],
      "source": [
        "# !wget https://pysource.com/extra_files/maskrcnn_colab_demo_commit_17.zip\n",
        "# !unzip maskrcnn_colab_demo_commit_17.zip\n",
        "# import sys\n",
        "# sys.path.append(\"/content/drive/MyDrive/mask_nail/maskrcnn_colab/mrcnn_demo\")\n",
        "# from m_rcnn import *\n",
        "# %matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvdia-smi"
      ],
      "metadata": {
        "id": "PTEi7TaD859M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6npLKIL3BqiO"
      },
      "source": [
        "## **4. Detection (test your model on a random image)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8uzE5U3BqiP"
      },
      "outputs": [],
      "source": [
        "# Test on a random image\n",
        "# %cd /content/drive/MyDrive/mask_nail/\n",
        "#thanujan"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ROOT_DIR = \"/content/drive/MyDrive/mask_nail/maskrcnn_colab/mrcnn_demo\"\n",
        "# %cd mrcnn_demo/"
      ],
      "metadata": {
        "id": "VYqi1tQv0G23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HbPDpotXXV08"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "# sys.path.append(\"/content/drive/MyDrive/mask_nail/maskrcnn_colab/mrcnn_demo\")\n",
        "sys.path.append(\"./maskrcnn_colab/mrcnn_demo\")\n",
        "from m_rcnn import *\n",
        "from visualize import random_colors, get_mask_contours, draw_mask\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zkci_XjX1SQ"
      },
      "outputs": [],
      "source": [
        "# %cd /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJQUehP48HAS"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# test_model, inference_config = load_inference_model(1, \"/content/drive/MyDrive/mask_nail/maskrcnn_colab/logs/object20230122T1637/mask_rcnn_object_0005.h5\")\n",
        "test_model, inference_config = load_inference_model(1, \"./mask_rcnn_object_0005.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inference_config.display()"
      ],
      "metadata": {
        "id": "z8daRtZCVW7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyZHMsj27FcA"
      },
      "outputs": [],
      "source": [
        "# Load Image\n",
        "# img = cv2.imread(\"/content/funger.jpeg\")\n",
        "img = cv2.imread(\"./test.jpg\")\n",
        "\n",
        "# test_model, inference_config = load_inference_model(1, \"/content/drive/MyDrive/mask_nail/maskrcnn_colab/logs/object20230118T0240/mask_rcnn_object_0005.h5\")\n",
        "image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Detect results\n",
        "r = test_model.detect([image])[0]"
      ],
      "metadata": {
        "id": "xy1EmqQTF2g9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7566-9z7foU"
      },
      "outputs": [],
      "source": [
        "# from google.colab.patches import cv2_imshow\n",
        "# Get Coordinates and show it on the image\n",
        "\n",
        "print(r[\"masks\"].shape)\n",
        "object_count = len(r[\"class_ids\"])\n",
        "colors = random_colors(object_count)\n",
        "colors = random_colors(object_count)\n",
        "for i in range(object_count):\n",
        "    # 1. Mask\n",
        "    mask = r[\"masks\"][:, :, i]\n",
        "    contours = get_mask_contours(mask)\n",
        "    for cnt in contours:\n",
        "        cv2.polylines(img, [cnt], True, colors[i], 2)\n",
        "        output = draw_mask(img, [cnt], colors[i])\n",
        "\n",
        "cv2.imshow(\"\", output)\n",
        "cv2.waitKey(0)\n",
        "\n",
        "# closing all open windows\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3I3G-RZubtNo"
      },
      "outputs": [],
      "source": [
        "#!susimport cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# Load Image\n",
        "img = cv2.imread(\"./b (30).jpg\")\n",
        "\n",
        "\n",
        "# test_model, inference_config = load_inference_model(1, \"./maskrcnn_colab/logs/object20230122T1637/mask_rcnn_object_0005.h5\")\n",
        "image_a = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Detect results\n",
        "r = test_model.detect([image_a])[0]\n",
        "colors = random_colors(80)\n",
        "# Get Coordinates and show it on the image\n",
        "object_count = len(r[\"class_ids\"])\n",
        "for i in range(object_count):\n",
        "    # 1. Mask\n",
        "    mask = r[\"masks\"][:, :, i]\n",
        "    contours = get_mask_contours(mask)\n",
        "    for cnt in contours:\n",
        "        # cv2.polylines(img_a, [cnt], True, colors[i], 2)\n",
        "        img_a = draw_mask(img, [cnt], colors[i])\n",
        "# cv2.imshow(img)\n",
        "\n",
        "# img = cv2.imread(\"/content/b (10).jpg\")\n",
        "pts = cnt\n",
        "\n",
        "## (1) Crop the bounding rect\n",
        "rect = cv2.boundingRect(pts)\n",
        "x,y,w,h = rect\n",
        "croped = img[y:y+h, x:x+w].copy()\n",
        "\n",
        "## (2) make mask\n",
        "pts = pts - pts.min(axis=0)\n",
        "\n",
        "mask = np.zeros(croped.shape[:2], np.uint8)\n",
        "cv2.drawContours(mask, [pts], -1, (255, 255, 255), -1, cv2.LINE_AA)\n",
        "\n",
        "## (3) do bit-op\n",
        "dst = cv2.bitwise_and(croped, croped, mask=mask)\n",
        "\n",
        "## (4) add the white background\n",
        "## (4) add the white background\n",
        "bg = np.ones_like(croped, np.uint8)*255\n",
        "cv2.bitwise_not(bg,bg, mask=mask)\n",
        "image = bg+ dst\n",
        "\n",
        "\n",
        "cv2.imshow(\"croped\", croped)\n",
        "cv2.imshow(\"mask\", mask)\n",
        "cv2.imshow(\"dst\", dst)\n",
        "cv2.imshow(\"image\", image)\n",
        "cv2.waitKey(0)\n",
        "\n",
        "# closing all open windows\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "brown_range = [(0, 0, 0), (170, 170, 170)]\n",
        "\n",
        "2\n",
        "# Define the replacement colors for green and brown\n",
        "brown_color = (139, 69, 19)\n",
        "\n",
        "# Convert the image to a numpy array\n",
        "image_array = np.array(image)\n",
        "\n",
        "\n",
        "# Replace the pixels in the brown range with the brown color\n",
        "brown_mask = cv2.inRange(image_array, brown_range[0], brown_range[1])\n",
        "image_array[np.where(brown_mask)] = brown_color\n",
        "\n",
        "# Convert the rest of the pixels to white\n",
        "# white_mask = cv2.bitwise_not(brown_mask)\n",
        "# image_array[np.where(white_mask)] = (255, 255, 255)\n",
        "white = np.array([255, 255, 255])   # white color value\n",
        "brown = np.array([139, 69, 19])      # brown color value\n",
        "green = np.array([0, 255, 0])       # green color value\n",
        "\n",
        "brown_mask = np.all(image_array == brown, axis=-1)\n",
        "non_white_brown_mask = np.logical_not(np.all(image_array == white, axis=-1) | brown_mask)\n",
        "image_array[non_white_brown_mask] = green  # modify non-white and non-brown pixels to green\n",
        "\n",
        "# Convert the numpy array back to an image\n",
        "segmented_image = Image.fromarray(image_array)\n",
        "\n",
        "plt.imshow(segmented_image)\n",
        "plt.show()\n",
        "\n",
        "# Convert the image to a NumPy array\n",
        "img_array = np.array(segmented_image)\n",
        "img_array_a = np.array(image)\n",
        "\n",
        "# Get the dimensions of the image\n",
        "height, width, channels = img_array.shape\n",
        "height_a, width_a, channels_a = img_array_a.shape\n",
        "output\n",
        "\n",
        "# Define the RGB color you want to find the area of distribution for\n",
        "rgb_color = [139, 69, 19] # for red\n",
        "white = [255, 255, 255]\n",
        "\n",
        "# Loop through the pixels of the image and count the number of pixels with the desired RGB color\n",
        "counter = 0\n",
        "for i in range(height):\n",
        "    for j in range(width):\n",
        "        if np.array_equal(img_array[i,j], rgb_color):\n",
        "            counter += 1\n",
        "\n",
        "counter_a = 0\n",
        "for i in range(height_a):\n",
        "    for j in range(width_a):\n",
        "        if not np.array_equal(img_array_a[i,j], white):\n",
        "            counter_a += 1\n",
        "\n",
        "print(f\"The area of distribution of the RGB color {rgb_color} is: {counter}\")\n",
        "print(f\"The distribution of non-white pixels in the image is: {counter_a}\")\n",
        "print(f\"percentage: {(counter/counter_a)*100}\")\n",
        "print('shape1',img_array.shape)\n",
        "print('shape2',img_array_a.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlT1AKUYrn8j"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "sub=counter_a-counter\n",
        "# Define the values and labels for the pie chart\n",
        "values = [sub,counter]\n",
        "labels = ['Green', 'Brown']\n",
        "colors = ['lime', 'saddlebrown']\n",
        "\n",
        "\n",
        "# Create the pie chart with percentage values\n",
        "plt.pie(values, labels=labels, autopct='%1.1f%%',colors=colors)\n",
        "\n",
        "# Set the title of the chart\n",
        "plt.title('Pie Chart')\n",
        "\n",
        "# Show the chart\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ImJqJTTax1V"
      },
      "source": [
        "# yellow nail"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhsKXDDla06l"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# Load Image\n",
        "img = cv2.imread(\"./n.jpg\")\n",
        "\n",
        "\n",
        "# test_model, inference_config = load_inference_model(1, \"./maskrcnn_colab/logs/object20230122T1637/mask_rcnn_object_0005.h5\")\n",
        "image_a = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Detect results\n",
        "r = test_model.detect([image_a])[0]\n",
        "colors = random_colors(80)\n",
        "# Get Coordinates and show it on the image\n",
        "object_count = len(r[\"class_ids\"])\n",
        "for i in range(object_count):\n",
        "    # 1. Mask\n",
        "    mask = r[\"masks\"][:, :, i]\n",
        "    contours = get_mask_contours(mask)\n",
        "    for cnt in contours:\n",
        "        # cv2.polylines(img_a, [cnt], True, colors[i], 2)\n",
        "        img_a = draw_mask(img, [cnt], colors[i])\n",
        "# cv2.imshow(img)\n",
        "\n",
        "# img = cv2.imread(\"/content/b (10).jpg\")\n",
        "pts = cnt\n",
        "\n",
        "## (1) Crop the bounding rect\n",
        "rect = cv2.boundingRect(pts)\n",
        "x,y,w,h = rect\n",
        "croped = img[y:y+h, x:x+w].copy()\n",
        "\n",
        "## (2) make mask\n",
        "pts = pts - pts.min(axis=0)\n",
        "\n",
        "mask = np.zeros(croped.shape[:2], np.uint8)\n",
        "cv2.drawContours(mask, [pts], -1, (255, 255, 255), -1, cv2.LINE_AA)\n",
        "\n",
        "## (3) do bit-op\n",
        "dst = cv2.bitwise_and(croped, croped, mask=mask)\n",
        "\n",
        "## (4) add the white background\n",
        "## (4) add the white background\n",
        "bg = np.ones_like(croped, np.uint8)*255\n",
        "cv2.bitwise_not(bg,bg, mask=mask)\n",
        "image = bg+ dst\n",
        "\n",
        "\n",
        "cv2.imshow(\"croped\", croped)\n",
        "cv2.imshow(\"mask\", mask)\n",
        "cv2.imshow(\"dst\", dst)\n",
        "cv2.imshow(\"image\", image)\n",
        "cv2.waitKey(0)\n",
        "\n",
        "# closing all open windows\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "brown_range = [(100, 10, 100), (250, 250, 200)]\n",
        "\n",
        "\n",
        "# Define the replacement colors for green and brown\n",
        "brown_color = (139, 69, 19)\n",
        "\n",
        "# Convert the image to a numpy array\n",
        "image_array = np.array(image)\n",
        "\n",
        "\n",
        "# Replace the pixels in the brown range with the brown color\n",
        "brown_mask = cv2.inRange(image_array, brown_range[0], brown_range[1])\n",
        "image_array[np.where(brown_mask)] = brown_color\n",
        "\n",
        "# Convert the rest of the pixels to white\n",
        "# white_mask = cv2.bitwise_not(brown_mask)\n",
        "# image_array[np.where(white_mask)] = (255, 255, 255)\n",
        "white = np.array([255, 255, 255])   # white color value\n",
        "brown = np.array([139, 69, 19])      # brown color value\n",
        "green = np.array([0, 255, 0])       # green color value\n",
        "\n",
        "brown_mask = np.all(image_array == brown, axis=-1)\n",
        "non_white_brown_mask = np.logical_not(np.all(image_array == white, axis=-1) | brown_mask)\n",
        "image_array[non_white_brown_mask] = green  # modify non-white and non-brown pixels to green\n",
        "\n",
        "# Convert the numpy array back to an image\n",
        "segmented_image = Image.fromarray(image_array)\n",
        "\n",
        "plt.imshow(segmented_image)\n",
        "plt.show()\n",
        "\n",
        "# Convert the image to a NumPy array\n",
        "img_array = np.array(segmented_image)\n",
        "img_array_a = np.array(image)\n",
        "\n",
        "# Get the dimensions of the image\n",
        "height, width, channels = img_array.shape\n",
        "height_a, width_a, channels_a = img_array_a.shape\n",
        "\n",
        "\n",
        "# Define the RGB color you want to find the area of distribution for\n",
        "rgb_color = [139, 69, 19] # for red\n",
        "white = [255, 255, 255]\n",
        "\n",
        "# Loop through the pixels of the image and count the number of pixels with the desired RGB color\n",
        "counter = 0\n",
        "for i in range(height):\n",
        "    for j in range(width):\n",
        "        if np.array_equal(img_array[i,j], rgb_color):\n",
        "            counter += 1\n",
        "\n",
        "counter_a = 0\n",
        "for i in range(height_a):\n",
        "    for j in range(width_a):\n",
        "        if not np.array_equal(img_array_a[i,j], white):\n",
        "            counter_a += 1\n",
        "\n",
        "print(f\"The area of distribution of the RGB color {rgb_color} is: {counter}\")\n",
        "print(f\"The distribution of non-white pixels in the image is: {counter_a}\")\n",
        "print(f\"percentage: {(counter/counter_a)*100}\")\n",
        "print('shape1',img_array.shape)\n",
        "print('shape2',img_array_a.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vN1M5UQsrj9_"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "sub=counter_a-counter\n",
        "# Define the values and labels for the pie chart\n",
        "values = [sub,counter]\n",
        "labels = ['Green', 'Brown']\n",
        "colors =  ['lime', 'saddlebrown']\n",
        "\n",
        "# Create the pie chart with percentage values\n",
        "plt.pie(values, labels=labels, autopct='%1.1f%%',colors=colors)\n",
        "\n",
        "# Set the title of the chart\n",
        "plt.title('Pie Chart')\n",
        "\n",
        "# Show the chart\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgHz0oBjlxjZ"
      },
      "source": [
        "# white nail"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iuRuu_OAc_nE"
      },
      "outputs": [],
      "source": [
        "# import cv2\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# from PIL import Image\n",
        "# Load Image\n",
        "img = cv2.imread(\"./n.jpg\")\n",
        "\n",
        "\n",
        "# test_model, inference_config = load_inference_model(1, \"/content/drive/MyDrive/mask_nail/maskrcnn_colab/logs/object20230122T1637/mask_rcnn_object_0005.h5\")\n",
        "image_a = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Detect results\n",
        "r = test_model.detect([image_a])[0]\n",
        "colors = random_colors(80)\n",
        "# Get Coordinates and show it on the image\n",
        "object_count = len(r[\"class_ids\"])\n",
        "for i in range(object_count):\n",
        "    # 1. Mask\n",
        "    mask = r[\"masks\"][:, :, i]\n",
        "    contours = get_mask_contours(mask)\n",
        "    for cnt in contours:\n",
        "        # cv2.polylines(img_a, [cnt], True, colors[i], 2)\n",
        "        img_a = draw_mask(img, [cnt], colors[i])\n",
        "# cv2_imshow(img)\n",
        "\n",
        "# img = cv2.imread(\"/content/b (10).jpg\")\n",
        "pts = cnt\n",
        "\n",
        "## (1) Crop the bounding rect\n",
        "rect = cv2.boundingRect(pts)\n",
        "x,y,w,h = rect\n",
        "croped = img[y:y+h, x:x+w].copy()\n",
        "\n",
        "## (2) make mask\n",
        "pts = pts - pts.min(axis=0)\n",
        "\n",
        "mask = np.zeros(croped.shape[:2], np.uint8)\n",
        "cv2.drawContours(mask, [pts], -1, (255, 255, 255), -1, cv2.LINE_AA)\n",
        "\n",
        "## (3) do bit-op\n",
        "dst = cv2.bitwise_and(croped, croped, mask=mask)\n",
        "\n",
        "## (4) add the white background\n",
        "## (4) add the white background\n",
        "bg = np.ones_like(croped, np.uint8)*255\n",
        "cv2.bitwise_not(bg,bg, mask=mask)\n",
        "image = bg+ dst\n",
        "\n",
        "\n",
        "cv2.imshow(\"croped\", croped)\n",
        "cv2.imshow(\"mask\", mask)\n",
        "cv2.imshow(\"dst\", dst)\n",
        "cv2.imshow(\"image\", image)\n",
        "cv2.waitKey(0)\n",
        "\n",
        "# closing all open windows\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "brown_range = [(160, 150, 160), (250, 250, 250)]\n",
        "\n",
        "\n",
        "# Define the replacement colors for green and brown\n",
        "brown_color = (139, 69, 19)\n",
        "\n",
        "# Convert the image to a numpy array\n",
        "image_array = np.array(image)\n",
        "\n",
        "\n",
        "# Replace the pixels in the brown range with the brown color\n",
        "brown_mask = cv2.inRange(image_array, brown_range[0], brown_range[1])\n",
        "image_array[np.where(brown_mask)] = brown_color\n",
        "\n",
        "# Convert the rest of the pixels to white\n",
        "# white_mask = cv2.bitwise_not(brown_mask)\n",
        "# image_array[np.where(white_mask)] = (255, 255, 255)\n",
        "white = np.array([255, 255, 255])   # white color value\n",
        "brown = np.array([139, 69, 19])      # brown color value\n",
        "green = np.array([0, 255, 0])       # green color value\n",
        "\n",
        "brown_mask = np.all(image_array == brown, axis=-1)\n",
        "non_white_brown_mask = np.logical_not(np.all(image_array == white, axis=-1) | brown_mask)\n",
        "image_array[non_white_brown_mask] = green  # modify non-white and non-brown pixels to green\n",
        "\n",
        "# Convert the numpy array back to an image\n",
        "segmented_image = Image.fromarray(image_array)\n",
        "\n",
        "plt.imshow(segmented_image)\n",
        "plt.show()\n",
        "\n",
        "# Convert the image to a NumPy array\n",
        "img_array = np.array(segmented_image)\n",
        "img_array_a = np.array(image)\n",
        "\n",
        "# Get the dimensions of the image\n",
        "height, width, channels = img_array.shape\n",
        "height_a, width_a, channels_a = img_array_a.shape\n",
        "\n",
        "\n",
        "# Define the RGB color you want to find the area of distribution for\n",
        "rgb_color = [139, 69, 19] # for red\n",
        "white = [255, 255, 255]\n",
        "\n",
        "# Loop through the pixels of the image and count the number of pixels with the desired RGB color\n",
        "counter = 0\n",
        "for i in range(height):\n",
        "    for j in range(width):\n",
        "        if np.array_equal(img_array[i,j], rgb_color):\n",
        "            counter += 1\n",
        "\n",
        "counter_a = 0\n",
        "for i in range(height_a):\n",
        "    for j in range(width_a):\n",
        "        if not np.array_equal(img_array_a[i,j], white):\n",
        "            counter_a += 1\n",
        "\n",
        "print(f\"The area of distribution of the RGB color {rgb_color} is: {counter}\")\n",
        "print(f\"The distribution of non-white pixels in the image is: {counter_a}\")\n",
        "print(f\"percentage: {(counter/counter_a)*100}\")\n",
        "print('shape1',img_array.shape)\n",
        "print('shape2',img_array_a.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RvTG2dH0mGLn"
      },
      "outputs": [],
      "source": [
        "#  import matplotlib.pyplot as plt\n",
        "sub=counter_a-counter\n",
        "# Define the values and labels for the pie chart\n",
        "values = [sub,counter]\n",
        "labels = ['Green', 'Brown']\n",
        "colors =  ['lime', 'saddlebrown']\n",
        "\n",
        "# Create the pie chart with percentage values\n",
        "plt.pie(values, labels=labels, autopct='%1.1f%%',colors=colors)\n",
        "\n",
        "# Set the title of the chart\n",
        "plt.title('Pie Chart')\n",
        "\n",
        "# Show the chart\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model, inference_config = load_inference_model(1, \"./maskrcnn_colab/logs/object20230122T1637/mask_rcnn_object_0005.h5\")\n",
        ""
      ],
      "metadata": {
        "id": "rcUXuaX1GV55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rq3xxi4UK09a"
      },
      "outputs": [],
      "source": [
        "# !pip install -U flask-cors\n",
        "# !pip install flask-ngrok\n",
        "# !pip uninstall -y flask-ngrok\n",
        "# !pip install flask-ngrok\n",
        "from flask import Flask,request, jsonify, g\n",
        "from flask_ngrok import run_with_ngrok\n",
        "\n",
        "import pickle\n",
        "from flask_cors import CORS, cross_origin\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.python.keras.backend import set_session"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EiqY39gWyUJd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_HZsRSzYPE-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5GcKUdeNqXKg"
      },
      "outputs": [],
      "source": [
        "# !ngrok authtoken 2ObJjzVK6m5Pnb0A3PEnKtFTkTL_56ACd4yKvSQPcS6UPNtBk\n",
        "\n",
        "# tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "# hello = tf.constant('Hello, TensorFlow!')\n",
        "\n",
        "# session = tf.compat.v1.Session()\n",
        "import os\n",
        "\n",
        "app = Flask(__name__)\n",
        "# sess = tf.Session()\n",
        "CORS(app)\n",
        "run_with_ngrok(app)\n",
        "\n",
        "\n",
        "test_model, inference_config = load_inference_model(1, \"./maskrcnn_colab/logs/object20230122T1637/mask_rcnn_object_0005.h5\")\n",
        "\n",
        "\n",
        "\n",
        "# class Inference:\n",
        "#   global graph\n",
        "#   __model = None\n",
        "#   __instance = None\n",
        "\n",
        "#   def __new__(cls,arg):\n",
        "#     if cls.__instance is None:\n",
        "#       cls.__instance = super().__new__(cls)\n",
        "#     return cls.__instance\n",
        "\n",
        "#   def getPrediction(self, img):\n",
        "#     with graph.as_default():\n",
        "#       try:\n",
        "#         return self.__model.detect([img], verbose=0)\n",
        "#       except Exception as e:\n",
        "#         print(e)\n",
        "\n",
        "#   def __init__(self, path):\n",
        "#     if self.__model == None:\n",
        "#       print(\"model set\")\n",
        "#       model, inference =  load_inference_model(1,path)\n",
        "#       self.__model = model\n",
        "\n",
        "\n",
        "\n",
        "# def load_model():\n",
        "#   global test_model\n",
        "#   global inference_config\n",
        "#   global graph\n",
        "#   # graph = tf.compat.v1.get_default_graph()\n",
        "\n",
        "#   with graph.as_default():\n",
        "#     test_model = Inference( \"./maskrcnn_colab/logs/object20230122T1637/mask_rcnn_object_0005.h5\")\n",
        "\n",
        "\n",
        "# @app.before_first_request\n",
        "# def before_first_request():\n",
        "#     load_model()\n",
        "\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return jsonify({\"Hello\":\"Welcome\"})\n",
        "\n",
        "@app.route('/upload_image', methods=['POST'])\n",
        "def upload_image():\n",
        "  global test_model\n",
        "  global graph\n",
        "  print(request.files)\n",
        "  print(request.form)\n",
        "  #return jsonify({\"Hello\":\"Welcome\"})\n",
        "  if 'image' in request.files:\n",
        "    image = request.files['image']\n",
        "    Nail_disease = request.form.get('nail_disease')\n",
        "    print(Nail_disease)\n",
        "    image.save(image.filename)\n",
        "    print(image.filename)\n",
        "    # Load Image\n",
        "    # Example file name\n",
        "    filename =image.filename\n",
        "    # Get the current working directory\n",
        "    cwd = os.getcwd()\n",
        "    # Join the file name with the current working directory to get the full file path\n",
        "    file_path = os.path.join(cwd, filename)\n",
        "\n",
        "    print(file_path)\n",
        "    if (Nail_disease==\"black nail\"):\n",
        "        brown_range = [(0, 0, 0), (150, 140, 150)]\n",
        "    elif (Nail_disease=='yellow nail'):\n",
        "        brown_range = [(100, 10, 100), (255, 250, 200)]\n",
        "    elif (Nail_disease=='white spot'):\n",
        "        brown_range = [(160, 150, 160), (250, 250, 250)]\n",
        "    else:\n",
        "        return (jsonify(\"Wrong disease\"))\n",
        "\n",
        "\n",
        "    img = cv2.imread(file_path)\n",
        "    print(img.shape)\n",
        "    # imageFileName = secure_filename(image.filename)\n",
        "    # image.save('./images/' + imageFileName)\n",
        "    # image = cv2.imread('./images/' + imageFileName)\n",
        "    # with session.as_default():\n",
        "    #     with session.graph.as_default():\n",
        "    # test_model, inference_config = load_inference_model(1, \"/content/drive/MyDrive/mask_nail/maskrcnn_colab/logs/object20230122T1637/mask_rcnn_object_0005.h5\")\n",
        "    test_model, inference_config = load_inference_model(1, \"./maskrcnn_colab/logs/object20230122T1637/mask_rcnn_object_0005.h5\")\n",
        "\n",
        "    image_a = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    result = test_model.detect([image_a], verbose=0)\n",
        "    r = result[0]\n",
        "\n",
        "\n",
        "    colors = random_colors(80)\n",
        "    # Get Coordinates and show it on the image\n",
        "\n",
        "    object_count = len(r[\"class_ids\"])\n",
        "    for i in range(object_count):\n",
        "        # 1. Mask\n",
        "        mask = r[\"masks\"][:, :, i]\n",
        "        contours = get_mask_contours(mask)\n",
        "        for cnt in contours:\n",
        "            cv2.polylines(image_a, [cnt], True, colors[i], 2)\n",
        "              # img_a = draw_mask(img, [cnt], colors[i])\n",
        "\n",
        "    # cv2_imshow(img)\n",
        "\n",
        "    # img = cv2.imread(\"/content/b (10).jpg\")\n",
        "    pts = cnt\n",
        "\n",
        "    ## (1) Crop the bounding rect\n",
        "    rect = cv2.boundingRect(pts)\n",
        "    x,y,w,h = rect\n",
        "    croped = img[y:y+h, x:x+w].copy()\n",
        "\n",
        "    ## (2) make mask\n",
        "    pts = pts - pts.min(axis=0)\n",
        "\n",
        "    mask = np.zeros(croped.shape[:2], np.uint8)\n",
        "    cv2.drawContours(mask, [pts], -1, (255, 255, 255), -1, cv2.LINE_AA)\n",
        "\n",
        "    ## (3) do bit-op\n",
        "    dst = cv2.bitwise_and(croped, croped, mask=mask)\n",
        "\n",
        "    ## (4) add the white background\n",
        "    ## (4) add the white background\n",
        "    bg = np.ones_like(croped, np.uint8)*255\n",
        "    cv2.bitwise_not(bg,bg, mask=mask)\n",
        "    image = bg+ dst\n",
        "\n",
        "\n",
        "    # cv2.imshow(croped)\n",
        "    # cv2.imshow(mask)\n",
        "    # cv2.imshow(dst)\n",
        "    # cv2.imshow(image)\n",
        "\n",
        "\n",
        "    # Define the replacement colors for green and brown\n",
        "    brown_color = (139, 69, 19)\n",
        "\n",
        "    # Convert the image to a numpy array\n",
        "    image_array = np.array(image)\n",
        "\n",
        "\n",
        "    # Replace the pixels in the brown range with the brown color\n",
        "    brown_mask = cv2.inRange(image_array, brown_range[0], brown_range[1])\n",
        "    image_array[np.where(brown_mask)] = brown_color\n",
        "\n",
        "    # Convert the rest of the pixels to white\n",
        "    white_mask = cv2.bitwise_not(brown_mask)\n",
        "    image_array[np.where(white_mask)] = (255, 255, 255)\n",
        "\n",
        "    # Convert the numpy array back to an image\n",
        "    segmented_image = Image.fromarray(image_array)\n",
        "\n",
        "    # plt.imshow(segmented_image)\n",
        "    # plt.show()\n",
        "\n",
        "    # Convert the image to a NumPy array\n",
        "    img_array = np.array(segmented_image)\n",
        "    img_array_a = np.array(image)\n",
        "\n",
        "    # Get the dimensions of the image\n",
        "    height, width, channels = img_array.shape\n",
        "    height_a, width_a, channels_a = img_array_a.shape\n",
        "\n",
        "\n",
        "    # Define the RGB color you want to find the area of distribution for\n",
        "    rgb_color = [139, 69, 19] # for red\n",
        "    white = [255, 255, 255]\n",
        "\n",
        "    # Loop through the pixels of the image and count the number of pixels with the desired RGB color\n",
        "    counter = 0\n",
        "    for i in range(height):\n",
        "      for j in range(width):\n",
        "        if np.array_equal(img_array[i,j], rgb_color):\n",
        "              counter += 1\n",
        "\n",
        "    counter_a = 0\n",
        "    for i in range(height_a):\n",
        "      for j in range(width_a):\n",
        "        if not np.array_equal(img_array_a[i,j], white):\n",
        "          counter_a += 1\n",
        "    print(f\"The area of distribution of the RGB color {rgb_color} is: {counter}\")\n",
        "    print(f\"The distribution of non-white pixels in the image is: {counter_a}\")\n",
        "    print(f\"percentage: {(counter/counter_a)*100}\")\n",
        "    print(\"hello\")\n",
        "    # pred('/content/b.PNG')\n",
        "    return(jsonify(math.ceil((counter/counter_a)*100)))\n",
        "\n",
        "\n",
        "app.run()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEkXYrVK0fN2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0QG2MmTSdENL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}